  branch-instructions OR branches                    [Hardware event]
  branch-misses                                      [Hardware event]
  bus-cycles                                         [Hardware event]
  cache-misses                                       [Hardware event]
  cache-references                                   [Hardware event]
  cpu-cycles OR cycles                               [Hardware event]
  instructions                                       [Hardware event]
  ref-cycles                                         [Hardware event]
  alignment-faults                                   [Software event]
  bpf-output                                         [Software event]
  context-switches OR cs                             [Software event]
  cpu-clock                                          [Software event]
  cpu-migrations OR migrations                       [Software event]
  dummy                                              [Software event]
  emulation-faults                                   [Software event]
  major-faults                                       [Software event]
  minor-faults                                       [Software event]
  page-faults OR faults                              [Software event]
  task-clock                                         [Software event]
  L1-dcache-load-misses                              [Hardware cache event]
  L1-dcache-loads                                    [Hardware cache event]
  L1-dcache-stores                                   [Hardware cache event]
  L1-icache-load-misses                              [Hardware cache event]
  LLC-load-misses                                    [Hardware cache event]
  LLC-loads                                          [Hardware cache event]
  LLC-store-misses                                   [Hardware cache event]
  LLC-stores                                         [Hardware cache event]
  branch-load-misses                                 [Hardware cache event]
  branch-loads                                       [Hardware cache event]
  dTLB-load-misses                                   [Hardware cache event]
  dTLB-loads                                         [Hardware cache event]
  dTLB-store-misses                                  [Hardware cache event]
  dTLB-stores                                        [Hardware cache event]
  iTLB-load-misses                                   [Hardware cache event]
  iTLB-loads                                         [Hardware cache event]
  node-load-misses                                   [Hardware cache event]
  node-loads                                         [Hardware cache event]
  node-store-misses                                  [Hardware cache event]
  node-stores                                        [Hardware cache event]
  branch-instructions OR cpu/branch-instructions/    [Kernel PMU event]
  branch-misses OR cpu/branch-misses/                [Kernel PMU event]
  bus-cycles OR cpu/bus-cycles/                      [Kernel PMU event]
  cache-misses OR cpu/cache-misses/                  [Kernel PMU event]
  cache-references OR cpu/cache-references/          [Kernel PMU event]
  cpu-cycles OR cpu/cpu-cycles/                      [Kernel PMU event]
  cstate_core/c3-residency/                          [Kernel PMU event]
  cstate_core/c6-residency/                          [Kernel PMU event]
  cstate_core/c7-residency/                          [Kernel PMU event]
  cstate_pkg/c2-residency/                           [Kernel PMU event]
  cstate_pkg/c3-residency/                           [Kernel PMU event]
  cstate_pkg/c6-residency/                           [Kernel PMU event]
  cstate_pkg/c7-residency/                           [Kernel PMU event]
  cycles-ct OR cpu/cycles-ct/                        [Kernel PMU event]
  cycles-t OR cpu/cycles-t/                          [Kernel PMU event]
  el-abort OR cpu/el-abort/                          [Kernel PMU event]
  el-capacity OR cpu/el-capacity/                    [Kernel PMU event]
  el-commit OR cpu/el-commit/                        [Kernel PMU event]
  el-conflict OR cpu/el-conflict/                    [Kernel PMU event]
  el-start OR cpu/el-start/                          [Kernel PMU event]
  instructions OR cpu/instructions/                  [Kernel PMU event]
  intel_bts//                                        [Kernel PMU event]
  mem-loads OR cpu/mem-loads/                        [Kernel PMU event]
  mem-stores OR cpu/mem-stores/                      [Kernel PMU event]
  msr/aperf/                                         [Kernel PMU event]
  msr/mperf/                                         [Kernel PMU event]
  msr/smi/                                           [Kernel PMU event]
  msr/tsc/                                           [Kernel PMU event]
  power/energy-cores/                                [Kernel PMU event]
  power/energy-gpu/                                  [Kernel PMU event]
  power/energy-pkg/                                  [Kernel PMU event]
  power/energy-ram/                                  [Kernel PMU event]
  ref-cycles OR cpu/ref-cycles/                      [Kernel PMU event]
  topdown-fetch-bubbles OR cpu/topdown-fetch-bubbles/ [Kernel PMU event]
  topdown-recovery-bubbles OR cpu/topdown-recovery-bubbles/ [Kernel PMU event]
  topdown-slots-issued OR cpu/topdown-slots-issued/  [Kernel PMU event]
  topdown-slots-retired OR cpu/topdown-slots-retired/ [Kernel PMU event]
  topdown-total-slots OR cpu/topdown-total-slots/    [Kernel PMU event]
  tx-abort OR cpu/tx-abort/                          [Kernel PMU event]
  tx-capacity OR cpu/tx-capacity/                    [Kernel PMU event]
  tx-commit OR cpu/tx-commit/                        [Kernel PMU event]
  tx-conflict OR cpu/tx-conflict/                    [Kernel PMU event]
  tx-start OR cpu/tx-start/                          [Kernel PMU event]
  uncore_cbox_0/clockticks/                          [Kernel PMU event]
  uncore_cbox_1/clockticks/                          [Kernel PMU event]
  uncore_cbox_2/clockticks/                          [Kernel PMU event]
  uncore_cbox_3/clockticks/                          [Kernel PMU event]
  rNNN                                               [Raw hardware event descriptor]
  cpu/t1=v1[,t2=v2,t3 ...]/modifier                  [Raw hardware event descriptor]
  mem:<addr>[/len][:access]                          [Hardware breakpoint]
perf list

  arith.divider_uops                          [Any uop executed by the Divider. (This includes all divide uops, sqrt, ...)]
  avx_insts.all                               [Note that a whole rep string only counts AVX_INST.ALL once.]
  baclears.any                                [Number of front end re-steers due to BPU misprediction.]
  br_inst_exec.all_branches                   [Counts all near executed branches (not necessarily retired).]
  br_inst_exec.all_conditional                [Speculative and retired macro-conditional branches.]
  br_inst_exec.all_direct_jmp                 [Speculative and retired macro-unconditional branches excluding calls and indirects.]
  br_inst_exec.all_direct_near_call           [Speculative and retired direct near calls.]
  br_inst_exec.all_indirect_jump_non_call_ret  [Speculative and retired indirect branches excluding calls and returns.]
  br_inst_exec.all_indirect_near_return       [Speculative and retired indirect return branches.]
  br_inst_exec.nontaken_conditional           [Not taken macro-conditional branches.]
  br_inst_exec.taken_conditional              [Taken speculative and retired macro-conditional branches.]
  br_inst_exec.taken_direct_jump              [Taken speculative and retired macro-conditional branch instructions excluding calls and indirects.]
  br_inst_exec.taken_direct_near_call         [Taken speculative and retired direct near calls.]
  br_inst_exec.taken_indirect_jump_non_call_ret  [Taken speculative and retired indirect branches excluding calls and returns.]
  br_inst_exec.taken_indirect_near_call       [Taken speculative and retired indirect calls.]
  br_inst_exec.taken_indirect_near_return     [Taken speculative and retired indirect branches with return mnemonic.]
  br_inst_retired.all_branches                [Branch instructions at retirement.]
  br_inst_retired.all_branches_pebs           [All (macro) branch instructions retired. (Uses PEBS)]
  br_inst_retired.conditional                 [Conditional branch instructions retired. (Supports PEBS)]
  br_inst_retired.far_branch                  [Number of far branches retired.]
  br_inst_retired.near_call                   [Direct and indirect near call instructions retired. (Supports PEBS)]
  br_inst_retired.near_call_r3                [Direct and indirect macro near call instructions retired (captured in ring 3). (Supports PEBS)]
  br_inst_retired.near_return                 [Return instructions retired. (Supports PEBS)]
  br_inst_retired.near_taken                  [Taken branch instructions retired. (Supports PEBS)]
  br_inst_retired.not_taken                   [Counts the number of not taken branch instructions retired.]
  br_misp_exec.all_branches                   [Counts all near executed branches (not necessarily retired).]
  br_misp_exec.all_conditional                [Speculative and retired mispredicted macro conditional branches.]
  br_misp_exec.all_indirect_jump_non_call_ret  [Mispredicted indirect branches excluding calls and returns.]
  br_misp_exec.nontaken_conditional           [Not taken speculative and retired mispredicted macro conditional branches.]
  br_misp_exec.taken_conditional              [Taken speculative and retired mispredicted macro conditional branches.]
  br_misp_exec.taken_indirect_jump_non_call_ret  [Taken speculative and retired mispredicted indirect branches excluding calls and returns.]
  br_misp_exec.taken_indirect_near_call       [Taken speculative and retired mispredicted indirect calls.]
  br_misp_exec.taken_return_near              [Taken speculative and retired mispredicted indirect branches with return mnemonic.]
  br_misp_retired.all_branches                [Mispredicted branch instructions at retirement.]
  br_misp_retired.all_branches_pebs           [This event counts all mispredicted branch instructions retired. This is a precise event. (Uses PEBS)]
  br_misp_retired.conditional                 [Mispredicted conditional branch instructions retired. (Supports PEBS)]
  br_misp_retired.near_taken                  [number of near branch instructions retired that were mispredicted and taken. (Supports PEBS)]
  cpl_cycles.ring0                            [Unhalted core cycles when the thread is in ring 0.]
  cpl_cycles.ring0_trans                      [Number of intervals between processor halts while thread is in ring 0.]
  cpl_cycles.ring123                          [Unhalted core cycles when the thread is not in ring 0.]
  cpu_clk_thread_unhalted.one_thread_active   [Count XClk pulses when this thread is unhalted and the other thread is halted.]
  cpu_clk_thread_unhalted.ref_xclk            [Increments at the frequency of XCLK (100 MHz) when not halted.]
  cpu_clk_thread_unhalted.ref_xclk_any        [Reference cycles when the at least one thread on the physical core is unhalted (counts at 100 MHz rate).]
  cpu_clk_unhalted.one_thread_active          [Count XClk pulses when this thread is unhalted and the other thread is halted.]
  cpu_clk_unhalted.ref_tsc                    [This event counts the number of reference cycles when the core is not in a halt state. The core enters the halt state when it is running the HLT instruction or the MWAIT instruction. This event is not affected by core frequency changes (for example, P states, TM2 transitions) but has the same incrementing frequency as the time stamp counter. This event can approximate elapsed time while the core was not in a halt state.]
  cpu_clk_unhalted.ref_xclk                   [Reference cycles when the thread is unhalted. (counts at 100 MHz rate)]
  cpu_clk_unhalted.ref_xclk_any               [Reference cycles when the at least one thread on the physical core is unhalted (counts at 100 MHz rate).]
  cpu_clk_unhalted.thread                     [This event counts the number of thread cycles while the thread is not in a halt state. The thread enters the halt state when it is running the HLT instruction. The core frequency may change from time to time due to power or thermal throttling.]
  cpu_clk_unhalted.thread_any                 [Core cycles when at least one thread on the physical core is not in halt state.]
  cpu_clk_unhalted.thread_p                   [Counts the number of thread cycles while the thread is not in a halt state. The thread enters the halt state when it is running the HLT instruction. The core frequency may change from time to time due to power or thermal throttling.]
  cpu_clk_unhalted.thread_p_any               [Core cycles when at least one thread on the physical core is not in halt state.]
  cycle_activity.cycles_l1d_pending           [Cycles with pending L1 data cache miss loads. Set Cmask=8 to count cycle.]
  cycle_activity.cycles_l2_pending            [Cycles with pending L2 miss loads. Set Cmask=2 to count cycle. Errata: HSD78]
  cycle_activity.cycles_ldm_pending           [Cycles with pending memory loads. Set Cmask=2 to count cycle.]
  cycle_activity.cycles_no_execute            [This event counts cycles during which no instructions were executed in the execution stage of the pipeline.]
  cycle_activity.stalls_l1d_pending           [Execution stalls due to L1 data cache miss loads. Set Cmask=0CH.]
  cycle_activity.stalls_l2_pending            [Number of loads missed L2.]
  cycle_activity.stalls_ldm_pending           [This event counts cycles during which no instructions were executed in the execution stage of the pipeline and there were memory instructions pending (waiting for data).]
  dsb2mite_switches.penalty_cycles            [Decode Stream Buffer (DSB)-to-MITE switch true penalty cycles.]
  dtlb_load_misses.miss_causes_a_walk         [Misses in all TLB levels that cause a page walk of any page size.]
  dtlb_load_misses.pde_cache_miss             [DTLB demand load misses with low part of linear-to-physical address translation missed.]
  dtlb_load_misses.stlb_hit                   [Number of cache load STLB hits. No page walk.]
  dtlb_load_misses.stlb_hit_2m                [This event counts load operations from a 2M page that miss the first DTLB level but hit the second and do not cause page walks.]
  dtlb_load_misses.stlb_hit_4k                [This event counts load operations from a 4K page that miss the first DTLB level but hit the second and do not cause page walks.]
  dtlb_load_misses.walk_completed             [Completed page walks in any TLB of any page size due to demand load misses.]
  dtlb_load_misses.walk_completed_1g          [Load miss in all TLB levels causes a page walk that completes. (1G)]
  dtlb_load_misses.walk_completed_2m_4m       [Completed page walks due to demand load misses that caused 2M/4M page walks in any TLB levels.]
  dtlb_load_misses.walk_completed_4k          [Completed page walks due to demand load misses that caused 4K page walks in any TLB levels.]
  dtlb_load_misses.walk_duration              [This event counts cycles when the  page miss handler (PMH) is servicing page walks caused by DTLB load misses.]
  dtlb_store_misses.miss_causes_a_walk        [Miss in all TLB levels causes a page walk of any page size (4K/2M/4M/1G).]
  dtlb_store_misses.pde_cache_miss            [DTLB store misses with low part of linear-to-physical address translation missed.]
  dtlb_store_misses.stlb_hit                  [Store operations that miss the first TLB level but hit the second and do not cause page walks.]
  dtlb_store_misses.stlb_hit_2m               [This event counts store operations from a 2M page that miss the first DTLB level but hit the second and do not cause page walks.]
  dtlb_store_misses.stlb_hit_4k               [This event counts store operations from a 4K page that miss the first DTLB level but hit the second and do not cause page walks.]
  dtlb_store_misses.walk_completed            [Completed page walks due to store miss in any TLB levels of any page size (4K/2M/4M/1G).]
  dtlb_store_misses.walk_completed_1g         [Store misses in all DTLB levels that cause completed page walks. (1G)]
  dtlb_store_misses.walk_completed_2m_4m      [Completed page walks due to store misses in one or more TLB levels of 2M/4M page structure.]
  dtlb_store_misses.walk_completed_4k         [Completed page walks due to store misses in one or more TLB levels of 4K page structure.]
  dtlb_store_misses.walk_duration             [This event counts cycles when the  page miss handler (PMH) is servicing page walks caused by DTLB store misses.]
  ept.walk_cycles                             [Cycle count for an Extended Page table walk.]
  fp_assist.any                               [Cycles with any input/output SSE* or FP assists.]
  fp_assist.simd_input                        [Number of SIMD FP assists due to input values.]
  fp_assist.simd_output                       [Number of SIMD FP assists due to output values.]
  fp_assist.x87_input                         [Number of X87 FP assists due to input values.]
  fp_assist.x87_output                        [Number of X87 FP assists due to output values.]
  hle_retired.aborted                         [Number of times an HLE execution aborted due to any reasons (multiple categories may count as one). (Supports PEBS)]
  hle_retired.aborted_misc1                   [Number of times an HLE execution aborted due to various memory events (e.g., read/write capacity and conflicts).]
  hle_retired.aborted_misc2                   [Number of times an HLE execution aborted due to uncommon conditions.]
  hle_retired.aborted_misc3                   [Number of times an HLE execution aborted due to HLE-unfriendly instructions.]
  hle_retired.aborted_misc4                   [Number of times an HLE execution aborted due to incompatible memory type. Errata: HSD65]
  hle_retired.aborted_misc5                   [Number of times an HLE execution aborted due to none of the previous 4 categories (e.g. interrupts).]
  hle_retired.commit                          [Number of times an HLE execution successfully committed.]
  hle_retired.start                           [Number of times an HLE execution started.]
  icache.hit                                  [Number of Instruction Cache, Streaming Buffer and Victim Cache Reads. both cacheable and noncacheable, including UC fetches.]
  icache.ifdata_stall                         [Cycles where a code fetch is stalled due to L1 instruction-cache miss.]
  icache.ifetch_stall                         [Cycles where a code fetch is stalled due to L1 instruction-cache miss.]
  icache.misses                               [This event counts Instruction Cache (ICACHE) misses.]
  idq.all_dsb_cycles_4_uops                   [Counts cycles DSB is delivered four uops. Set Cmask = 4.]
  idq.all_dsb_cycles_any_uops                 [Counts cycles DSB is delivered at least one uops. Set Cmask = 1.]
  idq.all_mite_cycles_4_uops                  [Counts cycles MITE is delivered four uops. Set Cmask = 4.]
  idq.all_mite_cycles_any_uops                [Counts cycles MITE is delivered at least one uop. Set Cmask = 1.]
  idq.dsb_cycles                              [Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from Decode Stream Buffer (DSB) path.]
  idq.dsb_uops                                [Increment each cycle. # of uops delivered to IDQ from DSB path. Set Cmask = 1 to count cycles.]
  idq.empty                                   [Counts cycles the IDQ is empty. Errata: HSD135]
  idq.mite_all_uops                           [Number of uops delivered to IDQ from any path.]
  idq.mite_cycles                             [Cycles when uops are being delivered to Instruction Decode Queue (IDQ) from MITE path.]
  idq.mite_uops                               [Increment each cycle # of uops delivered to IDQ from MITE path. Set Cmask = 1 to count cycles.]
  idq.ms_cycles                               [This event counts cycles during which the microcode sequencer assisted the Front-end in delivering uops.  Microcode assists are used for complex instructions or scenarios that can't be handled by the standard decoder.  Using other instructions, if possible, will usually improve performance.]
  idq.ms_dsb_cycles                           [Cycles when uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while Microcode Sequenser (MS) is busy.]
  idq.ms_dsb_occur                            [Deliveries to Instruction Decode Queue (IDQ) initiated by Decode Stream Buffer (DSB) while Microcode Sequenser (MS) is busy.]
  idq.ms_dsb_uops                             [Increment each cycle # of uops delivered to IDQ when MS_busy by DSB. Set Cmask = 1 to count cycles. Add Edge=1 to count # of delivery.]
  idq.ms_mite_uops                            [Increment each cycle # of uops delivered to IDQ when MS_busy by MITE. Set Cmask = 1 to count cycles.]
  idq.ms_switches                             [Number of switches from DSB (Decode Stream Buffer) or MITE (legacy decode pipeline) to the Microcode Sequencer.]
  idq.ms_uops                                 [This event counts uops delivered by the Front-end with the assistance of the microcode sequencer.  Microcode assists are used for complex instructions or scenarios that can't be handled by the standard decoder.  Using other instructions, if possible, will usually improve performance.]
  idq_uops_not_delivered.core                 [This event count the number of undelivered (unallocated) uops from the Front-end to the Resource Allocation Table (RAT) while the Back-end of the processor is not stalled. The Front-end can allocate up to 4 uops per cycle so this event can increment 0-4 times per cycle depending on the number of unallocated uops. This event is counted on a per-core basis. Errata: HSD135]
  idq_uops_not_delivered.cycles_0_uops_deliv.core  [This event counts the number cycles during which the Front-end allocated exactly zero uops to the Resource Allocation Table (RAT) while the Back-end of the processor is not stalled.  This event is counted on a per-core basis. Errata: HSD135]
  idq_uops_not_delivered.cycles_fe_was_ok     [Counts cycles FE delivered 4 uops or Resource Allocation Table (RAT) was stalling FE. Errata: HSD135]
  idq_uops_not_delivered.cycles_le_1_uop_deliv.core  [Cycles per thread when 3 or more uops are not delivered to Resource Allocation Table (RAT) when backend of the machine is not stalled. Errata: HSD135]
  idq_uops_not_delivered.cycles_le_2_uop_deliv.core  [Cycles with less than 2 uops delivered by the front end. Errata: HSD135]
  idq_uops_not_delivered.cycles_le_3_uop_deliv.core  [Cycles with less than 3 uops delivered by the front end. Errata: HSD135]
  ild_stall.iq_full                           [Stall cycles due to IQ is full.]
  ild_stall.lcp                               [This event counts cycles where the decoder is stalled on an instruction with a length changing prefix (LCP).]
  inst_retired.any                            [This event counts the number of instructions retired from execution. For instructions that consist of multiple micro-ops, this event counts the retirement of the last micro-op of the instruction. Counting continues during hardware interrupts, traps, and inside interrupt handlers. INST_RETIRED.ANY is counted by a designated fixed counter, leaving the programmable counters available for other events. Faulting executions of GETSEC/VM entry/VM Exit/MWait will not count as retired instructions. Errata: HSD140, HSD143]
  inst_retired.any_p                          [Number of instructions at retirement. Errata: HSD11, HSD140]
  inst_retired.prec_dist                      [Precise instruction retired event with HW to reduce effect of PEBS shadow in IP distribution. (Uses PEBS) Errata: HSD140]
  inst_retired.x87                            [This is a non-precise version (that is, does not use PEBS) of the event that counts FP operations retired. For X87 FP operations that have no exceptions counting also includes flows that have several X87, or flows that use X87 uops in the exception handling.]
  int_misc.recovery_cycles                    [This event counts the number of cycles spent waiting for a recovery after an event such as a processor nuke, JEClear, assist, hle/rtm abort etc.]
  int_misc.recovery_cycles_any                [Core cycles the allocator was stalled due to recovery from earlier clear event for any thread running on the physical core (e.g. misprediction or memory nuke).]
  itlb.itlb_flush                             [Counts the number of ITLB flushes, includes 4k/2M/4M pages.]
  itlb_misses.miss_causes_a_walk              [Misses in ITLB that causes a page walk of any page size.]
  itlb_misses.stlb_hit                        [ITLB misses that hit STLB. No page walk.]
  itlb_misses.stlb_hit_2m                     [ITLB misses that hit STLB (2M).]
  itlb_misses.stlb_hit_4k                     [ITLB misses that hit STLB (4K).]
  itlb_misses.walk_completed                  [Completed page walks in ITLB of any page size.]
  itlb_misses.walk_completed_1g               [Store miss in all TLB levels causes a page walk that completes. (1G)]
  itlb_misses.walk_completed_2m_4m            [Completed page walks due to misses in ITLB 2M/4M page entries.]
  itlb_misses.walk_completed_4k               [Completed page walks due to misses in ITLB 4K page entries.]
  itlb_misses.walk_duration                   [This event counts cycles when the  page miss handler (PMH) is servicing page walks caused by ITLB misses.]
  l1d.replacement                             [This event counts when new data lines are brought into the L1 Data cache, which cause other lines to be evicted from the cache.]
  l1d_pend_miss.fb_full                       [Cycles a demand request was blocked due to Fill Buffers inavailability.]
  l1d_pend_miss.pending                       [Increments the number of outstanding L1D misses every cycle. Set Cmask = 1 and Edge =1 to count occurrences.]
  l1d_pend_miss.pending_cycles                [Cycles with L1D load Misses outstanding.]
  l1d_pend_miss.pending_cycles_any            [Cycles with L1D load Misses outstanding from any thread on physical core.]
  l1d_pend_miss.request_fb_full               [Number of times a request needed a FB entry but there was no entry available for it. That is the FB unavailability was dominant reason for blocking the request. A request includes cacheable/uncacheable demands that is load, store or SW prefetch. HWP are e.]
  l2_demand_rqsts.wb_hit                      [Not rejected writebacks that hit L2 cache.]
  l2_lines_in.all                             [This event counts the number of L2 cache lines brought into the L2 cache.  Lines are filled into the L2 cache when there was an L2 miss.]
  l2_lines_in.e                               [L2 cache lines in E state filling L2.]
  l2_lines_in.i                               [L2 cache lines in I state filling L2.]
  l2_lines_in.s                               [L2 cache lines in S state filling L2.]
  l2_lines_out.demand_clean                   [Clean L2 cache lines evicted by demand.]
  l2_lines_out.demand_dirty                   [Dirty L2 cache lines evicted by demand.]
  l2_rqsts.all_code_rd                        [Counts all L2 code requests.]
  l2_rqsts.all_demand_data_rd                 [Counts any demand and L1 HW prefetch data load requests to L2. Errata: HSD78]
  l2_rqsts.all_demand_miss                    [Demand requests that miss L2 cache. Errata: HSD78]
  l2_rqsts.all_demand_references              [Demand requests to L2 cache. Errata: HSD78]
  l2_rqsts.all_pf                             [Counts all L2 HW prefetcher requests.]
  l2_rqsts.all_rfo                            [Counts all L2 store RFO requests.]
  l2_rqsts.code_rd_hit                        [Number of instruction fetches that hit the L2 cache.]
  l2_rqsts.code_rd_miss                       [Number of instruction fetches that missed the L2 cache.]
  l2_rqsts.demand_data_rd_hit                 [Demand data read requests that hit L2 cache. Errata: HSD78]
  l2_rqsts.demand_data_rd_miss                [Demand data read requests that missed L2, no rejects. Errata: HSD78]
  l2_rqsts.l2_pf_hit                          [Counts all L2 HW prefetcher requests that hit L2.]
  l2_rqsts.l2_pf_miss                         [Counts all L2 HW prefetcher requests that missed L2.]
  l2_rqsts.miss                               [All requests that missed L2. Errata: HSD78]
  l2_rqsts.references                         [All requests to L2 cache. Errata: HSD78]
  l2_rqsts.rfo_hit                            [Counts the number of store RFO requests that hit the L2 cache.]
  l2_rqsts.rfo_miss                           [Counts the number of store RFO requests that miss the L2 cache.]
  l2_trans.all_pf                             [Any MLC or L3 HW prefetch accessing L2, including rejects.]
  l2_trans.all_requests                       [Transactions accessing L2 pipe.]
  l2_trans.code_rd                            [L2 cache accesses when fetching instructions.]
  l2_trans.demand_data_rd                     [Demand data read requests that access L2 cache.]
  l2_trans.l1d_wb                             [L1D writebacks that access L2 cache.]
  l2_trans.l2_fill                            [L2 fill requests that access L2 cache.]
  l2_trans.l2_wb                              [L2 writebacks that access L2 cache.]
  l2_trans.rfo                                [RFO requests that access L2 cache.]
  ld_blocks.no_sr                             [The number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use.]
  ld_blocks.store_forward                     [This event counts loads that followed a store to the same address, where the data could not be forwarded inside the pipeline from the store to the load.  The most common reason why store forwarding would be blocked is when a load's address range overlaps with a preceding smaller uncompleted store. The penalty for blocked store forwarding is that the load must wait for the store to write its value to the cache before it can be issued.]
  ld_blocks_partial.address_alias             [Aliasing occurs when a load is issued after a store and their memory addresses are offset by 4K.  This event counts the number of loads that aliased with a preceding store, resulting in an extended address check in the pipeline which can have a performance impact.]
  load_hit_pre.hw_pf                          [Non-SW-prefetch load dispatches that hit fill buffer allocated for H/W prefetch.]
  load_hit_pre.sw_pf                          [Non-SW-prefetch load dispatches that hit fill buffer allocated for S/W prefetch.]
  lock_cycles.cache_lock_duration             [Cycles in which the L1D is locked.]
  lock_cycles.split_lock_uc_lock_duration     [Cycles in which the L1D and L2 are locked, due to a UC lock or split lock.]
  longest_lat_cache.miss                      [This event counts each cache miss condition for references to the last level cache.]
  longest_lat_cache.reference                 [This event counts requests originating from the core that reference a cache line in the last level cache.]
  lsd.cycles_4_uops                           [Cycles 4 Uops delivered by the LSD, but didn't come from the decoder.]
  lsd.cycles_active                           [Cycles Uops delivered by the LSD, but didn't come from the decoder.]
  lsd.uops                                    [Number of uops delivered by the LSD.]
  machine_clears.count                        [Number of machine clears (nukes) of any type.]
  machine_clears.cycles                       [Cycles there was a Nuke. Account for both thread-specific and All Thread Nukes.]
  machine_clears.maskmov                      [This event counts the number of executed Intel AVX masked load operations that refer to an illegal address range with the mask bits set to 0.]
  machine_clears.memory_ordering              [This event counts the number of memory ordering machine clears detected. Memory ordering machine clears can result from memory address aliasing or snoops from another hardware thread or core to data inflight in the pipeline.  Machine clears can have a significant performance impact if they are happening frequently.]
  machine_clears.smc                          [This event is incremented when self-modifying code (SMC) is detected, which causes a machine clear.  Machine clears can have a significant performance impact if they are happening frequently.]
  mem_load_uops_l3_hit_retired.xsnp_hit       [This event counts retired load uops that hit in the L3 cache, but required a cross-core snoop which resulted in a HIT in an on-pkg core cache. This does not include hardware prefetches. This is a precise event. (Supports PEBS) Errata: HSD29, HSD25, HSM26, HSM30]
  mem_load_uops_l3_hit_retired.xsnp_hitm      [This event counts retired load uops that hit in the L3 cache, but required a cross-core snoop which resulted in a HITM (hit modified) in an on-pkg core cache. This does not include hardware prefetches. This is a precise event. (Supports PEBS) Errata: HSD29, HSD25, HSM26, HSM30]
  mem_load_uops_l3_hit_retired.xsnp_miss      [Retired load uops which data sources were L3 hit and cross-core snoop missed in on-pkg core cache. (Supports PEBS) Errata: HSD29, HSD25, HSM26, HSM30]
  mem_load_uops_l3_hit_retired.xsnp_none      [Retired load uops which data sources were hits in L3 without snoops required. (Supports PEBS) Errata: HSD74, HSD29, HSD25, HSM26, HSM30]
  mem_load_uops_l3_miss_retired.local_dram    [This event counts retired load uops where the data came from local DRAM. This does not include hardware prefetches. This is a precise event. (Supports PEBS) Errata: HSD74, HSD29, HSD25, HSM30]
  mem_load_uops_retired.hit_lfb               [Retired load uops which data sources were load uops missed L1 but hit FB due to preceding miss to the same cache line with data not ready. (Supports PEBS) Errata: HSM30]
  mem_load_uops_retired.l1_hit                [Retired load uops with L1 cache hits as data sources. (Supports PEBS) Errata: HSD29, HSM30]
  mem_load_uops_retired.l1_miss               [This event counts retired load uops in which data sources missed in the L1 cache. This does not include hardware prefetches. This is a precise event. (Supports PEBS) Errata: HSM30]
  mem_load_uops_retired.l2_hit                [Retired load uops with L2 cache hits as data sources. (Supports PEBS) Errata: HSD76, HSD29, HSM30]
  mem_load_uops_retired.l2_miss               [Retired load uops with L2 cache misses as data sources. (Supports PEBS) Errata: HSD29, HSM30]
  mem_load_uops_retired.l3_hit                [This event counts retired load uops in which data sources were data hits in the L3 cache without snoops required. This does not include hardware prefetches. This is a precise event. (Supports PEBS) Errata: HSD74, HSD29, HSD25, HSM26, HSM30]
  mem_load_uops_retired.l3_miss               [Miss in last-level (L3) cache. Excludes Unknown data-source. (Supports PEBS) Errata: HSD74, HSD29, HSD25, HSM26, HSM30]
  mem_trans_retired.load_latency_gt_128       [Loads with latency value being above 128. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_16        [Loads with latency value being above 16. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_256       [Loads with latency value being above 256. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_32        [Loads with latency value being above 32. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_4         [Loads with latency value being above 4. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_512       [Loads with latency value being above 512. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_64        [Loads with latency value being above 64. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_trans_retired.load_latency_gt_8         [Loads with latency value being above 8. (Uses PEBS) Errata: HSD76, HSD25, HSM26]
  mem_uops_retired.all_loads                  [All retired load uops. (precise Event) (Supports PEBS) Errata: HSD29, HSM30]
  mem_uops_retired.all_stores                 [This event counts all store uops retired. This is a precise event. (Supports PEBS) Errata: HSD29, HSM30]
  mem_uops_retired.lock_loads                 [Retired load uops with locked access. (precise Event) (Supports PEBS) Errata: HSD76, HSD29, HSM30]
  mem_uops_retired.split_loads                [This event counts load uops retired which had memory addresses spilt across 2 cache lines. A line split is across 64B cache-lines which may include a page split (4K). This is a precise event. (Supports PEBS) Errata: HSD29, HSM30]
  mem_uops_retired.split_stores               [This event counts store uops retired which had memory addresses spilt across 2 cache lines. A line split is across 64B cache-lines which may include a page split (4K). This is a precise event. (Supports PEBS) Errata: HSD29, HSM30]
  mem_uops_retired.stlb_miss_loads            [Retired load uops that miss the STLB. (precise Event) (Supports PEBS) Errata: HSD29, HSM30]
  mem_uops_retired.stlb_miss_stores           [Retired store uops that miss the STLB. (precise Event) (Supports PEBS) Errata: HSD29, HSM30]
  misalign_mem_ref.loads                      [Speculative cache-line split load uops dispatched to L1D.]
  misalign_mem_ref.stores                     [Speculative cache-line split store-address uops dispatched to L1D.]
  move_elimination.int_eliminated             [Number of integer move elimination candidate uops that were eliminated.]
  move_elimination.int_not_eliminated         [Number of integer move elimination candidate uops that were not eliminated.]
  move_elimination.simd_eliminated            [Number of SIMD move elimination candidate uops that were eliminated.]
  move_elimination.simd_not_eliminated        [Number of SIMD move elimination candidate uops that were not eliminated.]
  offcore_requests.all_data_rd                [Data read requests sent to uncore (demand and prefetch).]
  offcore_requests.demand_code_rd             [Demand code read requests sent to uncore.]
  offcore_requests.demand_data_rd             [Demand data read requests sent to uncore. Errata: HSD78]
  offcore_requests.demand_rfo                 [Demand RFO read requests sent to uncore, including regular RFOs, locks, ItoM.]
  offcore_requests_buffer.sq_full             [Offcore requests buffer cannot take more entries for this thread core.]
  offcore_requests_outstanding.all_data_rd    [Offcore outstanding cacheable data read transactions in SQ to uncore. Set Cmask=1 to count cycles. Errata: HSD62, HSD61]
  offcore_requests_outstanding.cycles_with_data_rd  [Cycles when offcore outstanding cacheable Core Data Read transactions are present in SuperQueue (SQ), queue to uncore. Errata: HSD62, HSD61]
  offcore_requests_outstanding.cycles_with_demand_data_rd  [Cycles when offcore outstanding Demand Data Read transactions are present in SuperQueue (SQ), queue to uncore. Errata: HSD78, HSD62, HSD61]
  offcore_requests_outstanding.cycles_with_demand_rfo  [Offcore outstanding demand rfo reads transactions in SuperQueue (SQ), queue to uncore, every cycle. Errata: HSD62, HSD61]
  offcore_requests_outstanding.demand_code_rd  [Offcore outstanding Demand code Read transactions in SQ to uncore. Set Cmask=1 to count cycles. Errata: HSD62, HSD61]
  offcore_requests_outstanding.demand_data_rd  [Offcore outstanding demand data read transactions in SQ to uncore. Set Cmask=1 to count cycles. Errata: HSD78, HSD62, HSD61]
  offcore_requests_outstanding.demand_data_rd_ge_6  [Cycles with at least 6 offcore outstanding Demand Data Read transactions in uncore queue. Errata: HSD78, HSD62, HSD61]
  offcore_requests_outstanding.demand_rfo     [Offcore outstanding RFO store transactions in SQ to uncore. Set Cmask=1 to count cycles. Errata: HSD62, HSD61]
  offcore_response                            [Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_code_rd.l3_hit.any_response  [Counts all demand & prefetch code reads hit in the L3]
  offcore_response.all_code_rd.l3_hit.hit_other_core_no_fwd  [Counts all demand & prefetch code reads that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_code_rd.l3_hit.hitm_other_core  [Counts all demand & prefetch code reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.all_code_rd.l3_hit.no_snoop_needed  [Counts all demand & prefetch code reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_code_rd.l3_hit.snoop_miss  [Counts all demand & prefetch code reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_code_rd.l3_miss.any_response  [Counts all demand & prefetch code reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_code_rd.l3_miss.local_dram  [Counts all demand & prefetch code reads that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_data_rd.l3_hit.any_response  [Counts all demand & prefetch data reads hit in the L3]
  offcore_response.all_data_rd.l3_hit.hit_other_core_no_fwd  [Counts all demand & prefetch data reads that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_data_rd.l3_hit.hitm_other_core  [Counts all demand & prefetch data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_data_rd.l3_hit.no_snoop_needed  [Counts all demand & prefetch data reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_data_rd.l3_hit.snoop_miss  [Counts all demand & prefetch data reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_data_rd.l3_miss.any_response  [Counts all demand & prefetch data reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_data_rd.l3_miss.local_dram  [Counts all demand & prefetch data reads that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_pf_code_rd.l3_hit.any_response  [Counts all prefetch code reads hit in the L3]
  offcore_response.all_pf_code_rd.l3_hit.hit_other_core_no_fwd  [Counts all prefetch code reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.all_pf_code_rd.l3_hit.hitm_other_core  [Counts all prefetch code reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.all_pf_code_rd.l3_hit.no_snoop_needed  [Counts all prefetch code reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_pf_code_rd.l3_hit.snoop_miss  [Counts all prefetch code reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_pf_code_rd.l3_miss.any_response  [Counts all prefetch code reads miss in the L3]
  offcore_response.all_pf_code_rd.l3_miss.local_dram  [Counts all prefetch code reads miss the L3 and the data is returned from local dram]
  offcore_response.all_pf_data_rd.l3_hit.any_response  [Counts all prefetch data reads hit in the L3]
  offcore_response.all_pf_data_rd.l3_hit.hit_other_core_no_fwd  [Counts all prefetch data reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.all_pf_data_rd.l3_hit.hitm_other_core  [Counts all prefetch data reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.all_pf_data_rd.l3_hit.no_snoop_needed  [Counts all prefetch data reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_pf_data_rd.l3_hit.snoop_miss  [Counts all prefetch data reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_pf_data_rd.l3_miss.any_response  [Counts all prefetch data reads miss in the L3]
  offcore_response.all_pf_data_rd.l3_miss.local_dram  [Counts all prefetch data reads miss the L3 and the data is returned from local dram]
  offcore_response.all_pf_rfo.l3_hit.any_response  [Counts prefetch RFOs hit in the L3]
  offcore_response.all_pf_rfo.l3_hit.hit_other_core_no_fwd  [Counts prefetch RFOs hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.all_pf_rfo.l3_hit.hitm_other_core  [Counts prefetch RFOs hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.all_pf_rfo.l3_hit.no_snoop_needed  [Counts prefetch RFOs hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_pf_rfo.l3_hit.snoop_miss  [Counts prefetch RFOs hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_pf_rfo.l3_miss.any_response  [Counts prefetch RFOs miss in the L3]
  offcore_response.all_pf_rfo.l3_miss.local_dram  [Counts prefetch RFOs miss the L3 and the data is returned from local dram]
  offcore_response.all_reads.l3_hit.any_response  [Counts all data/code/rfo reads (demand & prefetch) hit in the L3]
  offcore_response.all_reads.l3_hit.hit_other_core_no_fwd  [Counts all data/code/rfo reads (demand & prefetch) that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_reads.l3_hit.hitm_other_core  [Counts all data/code/rfo reads (demand & prefetch) that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_reads.l3_hit.no_snoop_needed  [Counts all data/code/rfo reads (demand & prefetch) hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_reads.l3_hit.snoop_miss  [Counts all data/code/rfo reads (demand & prefetch) hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_reads.l3_miss.any_response  [Counts all data/code/rfo reads (demand & prefetch) that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_reads.l3_miss.local_dram  [Counts all data/code/rfo reads (demand & prefetch) that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_requests.l3_hit.any_response  [Counts all requests that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_requests.l3_hit.hit_other_core_no_fwd  [Counts all requests hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.all_requests.l3_hit.hitm_other_core  [Counts all requests hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.all_requests.l3_hit.no_snoop_needed  [Counts all requests hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_requests.l3_hit.snoop_miss  [Counts all requests hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_requests.l3_miss.any_response  [Counts all requests that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_requests.l3_miss.local_dram  [Counts all requests miss the L3 and the data is returned from local dram]
  offcore_response.all_rfo.l3_hit.any_response  [Counts all demand & prefetch RFOs hit in the L3]
  offcore_response.all_rfo.l3_hit.hit_other_core_no_fwd  [Counts all demand & prefetch RFOs that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_rfo.l3_hit.hitm_other_core  [Counts all demand & prefetch RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_rfo.l3_hit.no_snoop_needed  [Counts all demand & prefetch RFOs hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.all_rfo.l3_hit.snoop_miss  [Counts all demand & prefetch RFOs hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.all_rfo.l3_miss.any_response  [Counts all demand & prefetch RFOs that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.all_rfo.l3_miss.local_dram  [Counts all demand & prefetch RFOs that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_code_rd.l3_hit.any_response  [Counts all demand code reads hit in the L3]
  offcore_response.demand_code_rd.l3_hit.hit_other_core_no_fwd  [Counts all demand code reads that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_code_rd.l3_hit.hitm_other_core  [Counts all demand code reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_code_rd.l3_hit.no_snoop_needed  [Counts all demand code reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.demand_code_rd.l3_hit.snoop_miss  [Counts all demand code reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.demand_code_rd.l3_miss.any_response  [Counts all demand code reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_code_rd.l3_miss.local_dram  [Counts all demand code reads that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_data_rd.l3_hit.any_response  [Counts demand data reads hit in the L3]
  offcore_response.demand_data_rd.l3_hit.hit_other_core_no_fwd  [Counts demand data reads that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_data_rd.l3_hit.hitm_other_core  [Counts demand data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_data_rd.l3_hit.no_snoop_needed  [Counts demand data reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.demand_data_rd.l3_hit.snoop_miss  [Counts demand data reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.demand_data_rd.l3_miss.any_response  [Counts demand data reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_data_rd.l3_miss.local_dram  [Counts demand data reads that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_rfo.l3_hit.any_response  [Counts all demand data writes (RFOs) hit in the L3]
  offcore_response.demand_rfo.l3_hit.hit_other_core_no_fwd  [Counts all demand data writes (RFOs) that hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_rfo.l3_hit.hitm_other_core  [Counts all demand data writes (RFOs) that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_rfo.l3_hit.no_snoop_needed  [Counts all demand data writes (RFOs) hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.demand_rfo.l3_hit.snoop_miss  [Counts all demand data writes (RFOs) hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.demand_rfo.l3_miss.any_response  [Counts all demand data writes (RFOs) that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.demand_rfo.l3_miss.local_dram  [Counts all demand data writes (RFOs) that miss the L3 and the data is returned from local dram Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.other.l3_hit.any_response  [Counts any other requests hit in the L3]
  offcore_response.other.l3_hit.hit_other_core_no_fwd  [Counts any other requests hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.other.l3_hit.hitm_other_core  [Counts any other requests hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.other.l3_hit.no_snoop_needed  [Counts any other requests hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.other.l3_hit.snoop_miss    [Counts any other requests hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.other.l3_miss.any_response  [Counts any other requests miss in the L3]
  offcore_response.other.l3_miss.local_dram   [Counts any other requests miss the L3 and the data is returned from local dram]
  offcore_response.pf_l2_code_rd.l3_hit.any_response  [Counts all prefetch (that bring data to LLC only) code reads that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_code_rd.l3_hit.hit_other_core_no_fwd  [Counts all prefetch (that bring data to LLC only) code reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l2_code_rd.l3_hit.hitm_other_core  [Counts all prefetch (that bring data to LLC only) code reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l2_code_rd.l3_hit.no_snoop_needed  [Counts all prefetch (that bring data to LLC only) code reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l2_code_rd.l3_hit.snoop_miss  [Counts all prefetch (that bring data to LLC only) code reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l2_code_rd.l3_miss.any_response  [Counts all prefetch (that bring data to LLC only) code reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_code_rd.l3_miss.local_dram  [Counts all prefetch (that bring data to LLC only) code reads miss the L3 and the data is returned from local dram]
  offcore_response.pf_l2_data_rd.l3_hit.any_response  [Counts prefetch (that bring data to L2) data reads that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_data_rd.l3_hit.hit_other_core_no_fwd  [Counts prefetch (that bring data to L2) data reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l2_data_rd.l3_hit.hitm_other_core  [Counts prefetch (that bring data to L2) data reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l2_data_rd.l3_hit.no_snoop_needed  [Counts prefetch (that bring data to L2) data reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l2_data_rd.l3_hit.snoop_miss  [Counts prefetch (that bring data to L2) data reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l2_data_rd.l3_miss.any_response  [Counts prefetch (that bring data to L2) data reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_data_rd.l3_miss.local_dram  [Counts prefetch (that bring data to L2) data reads miss the L3 and the data is returned from local dram]
  offcore_response.pf_l2_rfo.l3_hit.any_response  [Counts all prefetch (that bring data to L2) RFOs that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_rfo.l3_hit.hit_other_core_no_fwd  [Counts all prefetch (that bring data to L2) RFOs hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l2_rfo.l3_hit.hitm_other_core  [Counts all prefetch (that bring data to L2) RFOs hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l2_rfo.l3_hit.no_snoop_needed  [Counts all prefetch (that bring data to L2) RFOs hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l2_rfo.l3_hit.snoop_miss  [Counts all prefetch (that bring data to L2) RFOs hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l2_rfo.l3_miss.any_response  [Counts all prefetch (that bring data to L2) RFOs that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l2_rfo.l3_miss.local_dram  [Counts all prefetch (that bring data to L2) RFOs miss the L3 and the data is returned from local dram]
  offcore_response.pf_l3_code_rd.l3_hit.any_response  [Counts prefetch (that bring data to LLC only) code reads that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_code_rd.l3_hit.hit_other_core_no_fwd  [Counts prefetch (that bring data to LLC only) code reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l3_code_rd.l3_hit.hitm_other_core  [Counts prefetch (that bring data to LLC only) code reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l3_code_rd.l3_hit.no_snoop_needed  [Counts prefetch (that bring data to LLC only) code reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l3_code_rd.l3_hit.snoop_miss  [Counts prefetch (that bring data to LLC only) code reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l3_code_rd.l3_miss.any_response  [Counts prefetch (that bring data to LLC only) code reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_code_rd.l3_miss.local_dram  [Counts prefetch (that bring data to LLC only) code reads miss the L3 and the data is returned from local dram]
  offcore_response.pf_l3_data_rd.l3_hit.any_response  [Counts all prefetch (that bring data to LLC only) data reads that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_data_rd.l3_hit.hit_other_core_no_fwd  [Counts all prefetch (that bring data to LLC only) data reads hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l3_data_rd.l3_hit.hitm_other_core  [Counts all prefetch (that bring data to LLC only) data reads hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l3_data_rd.l3_hit.no_snoop_needed  [Counts all prefetch (that bring data to LLC only) data reads hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l3_data_rd.l3_hit.snoop_miss  [Counts all prefetch (that bring data to LLC only) data reads hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l3_data_rd.l3_miss.any_response  [Counts all prefetch (that bring data to LLC only) data reads that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_data_rd.l3_miss.local_dram  [Counts all prefetch (that bring data to LLC only) data reads miss the L3 and the data is returned from local dram]
  offcore_response.pf_l3_rfo.l3_hit.any_response  [Counts all prefetch (that bring data to LLC only) RFOs  that hit in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_rfo.l3_hit.hit_other_core_no_fwd  [Counts all prefetch (that bring data to LLC only) RFOs hit in the L3 and the snoops to sibling cores hit in either E/S state and the line is not forwarded]
  offcore_response.pf_l3_rfo.l3_hit.hitm_other_core  [Counts all prefetch (that bring data to LLC only) RFOs hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded]
  offcore_response.pf_l3_rfo.l3_hit.no_snoop_needed  [Counts all prefetch (that bring data to LLC only) RFOs hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores]
  offcore_response.pf_l3_rfo.l3_hit.snoop_miss  [Counts all prefetch (that bring data to LLC only) RFOs hit in the L3 and the snoops sent to sibling cores return clean response]
  offcore_response.pf_l3_rfo.l3_miss.any_response  [Counts all prefetch (that bring data to LLC only) RFOs  that miss in the L3 Offcore response can be programmed only with a specific pair of event select and counter MSR, and with specific event codes and predefine mask bit value in a dedicated MSR to specify attributes of the offcore transaction.]
  offcore_response.pf_l3_rfo.l3_miss.local_dram  [Counts all prefetch (that bring data to LLC only) RFOs miss the L3 and the data is returned from local dram]
  other_assists.any_wb_assist                 [Number of microcode assists invoked by HW upon uop writeback.]
  other_assists.avx_to_sse                    [Number of transitions from AVX-256 to legacy SSE when penalty applicable. Errata: HSD56, HSM57]
  other_assists.sse_to_avx                    [Number of transitions from SSE to AVX-256 when penalty applicable. Errata: HSD56, HSM57]
  page_walker_loads.dtlb_l1                   [Number of DTLB page walker loads that hit in the L1+FB.]
  page_walker_loads.dtlb_l2                   [Number of DTLB page walker loads that hit in the L2.]
  page_walker_loads.dtlb_l3                   [Number of DTLB page walker loads that hit in the L3. Errata: HSD25]
  page_walker_loads.dtlb_memory               [Number of DTLB page walker loads from memory. Errata: HSD25]
  page_walker_loads.ept_dtlb_l1               [Counts the number of Extended Page Table walks from the DTLB that hit in the L1 and FB.]
  page_walker_loads.ept_dtlb_l2               [Counts the number of Extended Page Table walks from the DTLB that hit in the L2.]
  page_walker_loads.ept_dtlb_l3               [Counts the number of Extended Page Table walks from the DTLB that hit in the L3.]
  page_walker_loads.ept_dtlb_memory           [Counts the number of Extended Page Table walks from the DTLB that hit in memory.]
  page_walker_loads.ept_itlb_l1               [Counts the number of Extended Page Table walks from the ITLB that hit in the L1 and FB.]
  page_walker_loads.ept_itlb_l2               [Counts the number of Extended Page Table walks from the ITLB that hit in the L2.]
  page_walker_loads.ept_itlb_l3               [Counts the number of Extended Page Table walks from the ITLB that hit in the L2.]
  page_walker_loads.ept_itlb_memory           [Counts the number of Extended Page Table walks from the ITLB that hit in memory.]
  page_walker_loads.itlb_l1                   [Number of ITLB page walker loads that hit in the L1+FB.]
  page_walker_loads.itlb_l2                   [Number of ITLB page walker loads that hit in the L2.]
  page_walker_loads.itlb_l3                   [Number of ITLB page walker loads that hit in the L3. Errata: HSD25]
  page_walker_loads.itlb_memory               [Number of ITLB page walker loads from memory. Errata: HSD25]
  resource_stalls.any                         [Cycles allocation is stalled due to resource related reason. Errata: HSD135]
  resource_stalls.rob                         [Cycles stalled due to re-order buffer full.]
  resource_stalls.rs                          [Cycles stalled due to no eligible RS entry available.]
  resource_stalls.sb                          [This event counts cycles during which no instructions were allocated because no Store Buffers (SB) were available.]
  rob_misc_events.lbr_inserts                 [Count cases of saving new LBR records by hardware.]
  rs_events.empty_cycles                      [This event counts cycles when the Reservation Station ( RS ) is empty for the thread. The RS is a structure that buffers allocated micro-ops from the Front-end. If there are many cycles when the RS is empty, it may represent an underflow of instructions delivered from the Front-end.]
  rs_events.empty_end                         [Counts end of periods where the Reservation Station (RS) was empty. Could be useful to precisely locate Frontend Latency Bound issues.]
  rtm_retired.aborted                         [Number of times an RTM execution aborted due to any reasons (multiple categories may count as one). (Supports PEBS)]
  rtm_retired.aborted_misc1                   [Number of times an RTM execution aborted due to various memory events (e.g. read/write capacity and conflicts).]
  rtm_retired.aborted_misc2                   [Number of times an RTM execution aborted due to various memory events (e.g., read/write capacity and conflicts).]
  rtm_retired.aborted_misc3                   [Number of times an RTM execution aborted due to HLE-unfriendly instructions.]
  rtm_retired.aborted_misc4                   [Number of times an RTM execution aborted due to incompatible memory type. Errata: HSD65]
  rtm_retired.aborted_misc5                   [Number of times an RTM execution aborted due to none of the previous 4 categories (e.g. interrupt).]
  rtm_retired.commit                          [Number of times an RTM execution successfully committed.]
  rtm_retired.start                           [Number of times an RTM execution started.]
  sq_misc.split_lock                          []
  tlb_flush.dtlb_thread                       [DTLB flush attempts of the thread-specific entries.]
  tlb_flush.stlb_any                          [Count number of STLB flush attempts.]
  tx_exec.misc1                               [Counts the number of times a class of instructions that may cause a transactional abort was executed. Since this is the count of execution, it may not always cause a transactional abort.]
  tx_exec.misc2                               [Counts the number of times a class of instructions (e.g., vzeroupper) that may cause a transactional abort was executed inside a transactional region.]
  tx_exec.misc3                               [Counts the number of times an instruction execution caused the transactional nest count supported to be exceeded.]
  tx_exec.misc4                               [Counts the number of times a XBEGIN instruction was executed inside an HLE transactional region.]
  tx_exec.misc5                               [Counts the number of times an HLE XACQUIRE instruction was executed inside an RTM transactional region.]
  tx_mem.abort_capacity_write                 [Number of times a transactional abort was signaled due to a data capacity limitation for transactional writes.]
  tx_mem.abort_conflict                       [Number of times a transactional abort was signaled due to a data conflict on a transactionally accessed address.]
  tx_mem.abort_hle_elision_buffer_mismatch    [Number of times an HLE transactional execution aborted due to XRELEASE lock not satisfying the address and value requirements in the elision buffer.]
  tx_mem.abort_hle_elision_buffer_not_empty   [Number of times an HLE transactional execution aborted due to NoAllocatedElisionBuffer being non-zero.]
  tx_mem.abort_hle_elision_buffer_unsupported_alignment  [Number of times an HLE transactional execution aborted due to an unsupported read alignment from the elision buffer.]
  tx_mem.abort_hle_store_to_elided_lock       [Number of times a HLE transactional region aborted due to a non XRELEASE prefixed instruction writing to an elided lock in the elision buffer.]
  tx_mem.hle_elision_buffer_full              [Number of times HLE lock could not be elided due to ElisionBufferAvailable being zero.]
  uops_dispatched_port.port_0                 [Cycles per thread when uops are executed in port 0.]
  uops_dispatched_port.port_1                 [Cycles per thread when uops are executed in port 1.]
  uops_dispatched_port.port_2                 [Cycles per thread when uops are executed in port 2.]
  uops_dispatched_port.port_3                 [Cycles per thread when uops are executed in port 3.]
  uops_dispatched_port.port_4                 [Cycles per thread when uops are executed in port 4.]
  uops_dispatched_port.port_5                 [Cycles per thread when uops are executed in port 5.]
  uops_dispatched_port.port_6                 [Cycles per thread when uops are executed in port 6.]
  uops_dispatched_port.port_7                 [Cycles per thread when uops are executed in port 7.]
  uops_executed.core                          [Counts total number of uops to be executed per-core each cycle. Errata: HSD30, HSM31]
  uops_executed.core_cycles_ge_1              [Cycles at least 1 micro-op is executed from any thread on physical core. Errata: HSD30, HSM31]
  uops_executed.core_cycles_ge_2              [Cycles at least 2 micro-op is executed from any thread on physical core. Errata: HSD30, HSM31]
  uops_executed.core_cycles_ge_3              [Cycles at least 3 micro-op is executed from any thread on physical core. Errata: HSD30, HSM31]
  uops_executed.core_cycles_ge_4              [Cycles at least 4 micro-op is executed from any thread on physical core. Errata: HSD30, HSM31]
  uops_executed.core_cycles_none              [Cycles with no micro-ops executed from any thread on physical core. Errata: HSD30, HSM31]
  uops_executed.cycles_ge_1_uop_exec          [This events counts the cycles where at least one uop was executed. It is counted per thread. Errata: HSD144, HSD30, HSM31]
  uops_executed.cycles_ge_2_uops_exec         [This events counts the cycles where at least two uop were executed. It is counted per thread. Errata: HSD144, HSD30, HSM31]
  uops_executed.cycles_ge_3_uops_exec         [This events counts the cycles where at least three uop were executed. It is counted per thread. Errata: HSD144, HSD30, HSM31]
  uops_executed.cycles_ge_4_uops_exec         [Cycles where at least 4 uops were executed per-thread. Errata: HSD144, HSD30, HSM31]
  uops_executed.stall_cycles                  [Counts number of cycles no uops were dispatched to be executed on this thread. Errata: HSD144, HSD30, HSM31]
  uops_executed_port.port_0                   [Cycles which a uop is dispatched on port 0 in this thread.]
  uops_executed_port.port_0_core              [Cycles per core when uops are exectuted in port 0.]
  uops_executed_port.port_1                   [Cycles which a uop is dispatched on port 1 in this thread.]
  uops_executed_port.port_1_core              [Cycles per core when uops are exectuted in port 1.]
  uops_executed_port.port_2                   [Cycles which a uop is dispatched on port 2 in this thread.]
  uops_executed_port.port_2_core              [Cycles per core when uops are dispatched to port 2.]
  uops_executed_port.port_3                   [Cycles which a uop is dispatched on port 3 in this thread.]
  uops_executed_port.port_3_core              [Cycles per core when uops are dispatched to port 3.]
  uops_executed_port.port_4                   [Cycles which a uop is dispatched on port 4 in this thread.]
  uops_executed_port.port_4_core              [Cycles per core when uops are exectuted in port 4.]
  uops_executed_port.port_5                   [Cycles which a uop is dispatched on port 5 in this thread.]
  uops_executed_port.port_5_core              [Cycles per core when uops are exectuted in port 5.]
  uops_executed_port.port_6                   [Cycles which a uop is dispatched on port 6 in this thread.]
  uops_executed_port.port_6_core              [Cycles per core when uops are exectuted in port 6.]
  uops_executed_port.port_7                   [Cycles which a uop is dispatched on port 7 in this thread.]
  uops_executed_port.port_7_core              [Cycles per core when uops are dispatched to port 7.]
  uops_issued.any                             [This event counts the number of uops issued by the Front-end of the pipeline to the Back-end. This event is counted at the allocation stage and will count both retired and non-retired uops.]
  uops_issued.core_stall_cycles               [Cycles when Resource Allocation Table (RAT) does not issue Uops to Reservation Station (RS) for all threads.]
  uops_issued.flags_merge                     [Number of flags-merge uops allocated. Such uops add delay.]
  uops_issued.single_mul                      [Number of multiply packed/scalar single precision uops allocated.]
  uops_issued.slow_lea                        [Number of slow LEA or similar uops allocated. Such uop has 3 sources (for example, 2 sources + immediate) regardless of whether it is a result of LEA instruction or not.]
  uops_issued.stall_cycles                    [Cycles when Resource Allocation Table (RAT) does not issue Uops to Reservation Station (RS) for the thread.]
  uops_retired.all                            [Actually retired uops. (Supports PEBS)]
  uops_retired.core_stall_cycles              [Cycles without actually retired uops.]
  uops_retired.retire_slots                   [Retirement slots used. (Supports PEBS)]
  uops_retired.stall_cycles                   [Cycles without actually retired uops.]
  uops_retired.total_cycles                   [Cycles with less than 10 actually retired uops.]
  unc_arb_coh_trk_occupancy.all               [Each cycle count number of valid entries in Coherency Tracker queue from allocation till deallocation. Aperture requests (snoops) appear as NC decoded internally and become coherent (snoop L3, access memory).]
  unc_arb_coh_trk_requests.all                [Number of entries allocated. Account for Any type: e.g. Snoop, Core aperture, etc.]
  unc_arb_trk_occupancy.all                   [Each cycle count number of all Core outgoing valid entries. Such entry is defined as valid from it's allocation till first of IDI0 or DRS0 messages is sent out. Accounts for Coherent and non-coherent traffic.]
  unc_arb_trk_occupancy.cycles_with_any_request  []
  unc_arb_trk_requests.all                    [Total number of Core outgoing entries allocated. Accounts for Coherent and non-coherent traffic.]
  unc_arb_trk_requests.writes                 [Number of Writes allocated - any write transactions: full/partials writes and evictions.]
  unc_cbo_cache_lookup.any_es                 [L3 Lookup any request that access cache and found line in E or S-state.]
  unc_cbo_cache_lookup.any_i                  [L3 Lookup any request that access cache and found line in I-state.]
  unc_cbo_cache_lookup.any_m                  [L3 Lookup any request that access cache and found line in M-state.]
  unc_cbo_cache_lookup.any_mesi               [L3 Lookup any request that access cache and found line in MESI-state.]
  unc_cbo_cache_lookup.extsnp_es              [L3 Lookup external snoop request that access cache and found line in E or S-state.]
  unc_cbo_cache_lookup.extsnp_i               [L3 Lookup external snoop request that access cache and found line in I-state.]
  unc_cbo_cache_lookup.extsnp_m               [L3 Lookup external snoop request that access cache and found line in M-state.]
  unc_cbo_cache_lookup.extsnp_mesi            [L3 Lookup external snoop request that access cache and found line in MESI-state.]
  unc_cbo_cache_lookup.read_es                [L3 Lookup read request that access cache and found line in E or S-state.]
  unc_cbo_cache_lookup.read_i                 [L3 Lookup read request that access cache and found line in I-state.]
  unc_cbo_cache_lookup.read_m                 [L3 Lookup read request that access cache and found line in M-state.]
  unc_cbo_cache_lookup.read_mesi              [L3 Lookup read request that access cache and found line in any MESI-state.]
  unc_cbo_cache_lookup.write_es               [L3 Lookup write request that access cache and found line in E or S-state.]
  unc_cbo_cache_lookup.write_i                [L3 Lookup write request that access cache and found line in I-state.]
  unc_cbo_cache_lookup.write_m                [L3 Lookup write request that access cache and found line in M-state.]
  unc_cbo_cache_lookup.write_mesi             [L3 Lookup write request that access cache and found line in MESI-state.]
  unc_cbo_xsnp_response.hit_eviction          [A cross-core snoop resulted from L3 Eviction which hits a non-modified line in some processor core.]
  unc_cbo_xsnp_response.hit_external          [An external snoop hits a non-modified line in some processor core.]
  unc_cbo_xsnp_response.hit_xcore             [A cross-core snoop initiated by this Cbox due to processor core memory request which hits a non-modified line in some processor core.]
  unc_cbo_xsnp_response.hitm_eviction         [A cross-core snoop resulted from L3 Eviction which hits a modified line in some processor core.]
  unc_cbo_xsnp_response.hitm_external         [An external snoop hits a modified line in some processor core.]
  unc_cbo_xsnp_response.hitm_xcore            [A cross-core snoop initiated by this Cbox due to processor core memory request which hits a modified line in some processor core.]
  unc_cbo_xsnp_response.miss_eviction         [A cross-core snoop resulted from L3 Eviction which misses in some processor core.]
  unc_cbo_xsnp_response.miss_external         [An external snoop misses in some processor core.]
  unc_cbo_xsnp_response.miss_xcore            [A cross-core snoop initiated by this Cbox due to processor core memory request which misses in some processor core.]
  unc_clock.socket                            [This 48-bit fixed counter counts the UCLK cycles.]
